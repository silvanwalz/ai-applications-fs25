{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 10: Logistische Regression und erweiterte Performance Masse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lernziele\n",
    "\n",
    "* Idee und Modell der Logistischen Regression verstehen.\n",
    "* Konzept von Fehler bzw. Cost-Functions und Fehler-/Cost-Function der Logistischen Regression.\n",
    "* Prognose von Klassenzugehörigkeit mittels Threshold.\n",
    "* Prognsotizieren von Wahrscheinlichkeiten und Klassenzugheörigkeit.\n",
    "* Confusion-Matrix, Vorhersagegenauigkeit, True Positive Rate und False Positive Rate.\n",
    "* ROC-Kurve und AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Das logistische Regressionsmodell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook lernen wir einen neuen Machine Learning Algorithmus für Klassifikationsprobleme kennen: die **Logistische Regression**.\n",
    "\n",
    "Obwohl der Name das Wort 'Regression' beinhaltet, ist die Logistische Regression ein bei **Klassifikationsproblemen** verwendetes Modell. Anders als das kNN-Modell, welches **direkt** die Klassenzugehörigkeit vorhersagt, liefert die Logistische Regression aber zunächst eine Vorhersage der **Wahrscheinlichkeit einer bestimmten Klassenzugehörigkeit**.\n",
    "\n",
    "Um die Logistische Regression kennen zu lernen, verwenden wir hier einen (realen) Datensatz, der für verschiedene Unternehmen als Features einige wichtige Finanzkennzahlen enthält ('Accounting Ratios' wie z.B. das Dept-to-Equity Ratio, im folgenden werden wir diese Kennzahlen schlicht 'ratio' nennen). Als Label haben wir zu jedem Unternehmen die Information, ob es zahlungsunfähig wurde ('Default') oder nicht ('non-Default'). Aufgabe des Machine Learning Algorithmus Logistische Regression wird es also sein, auf Basis der Angaben der Finanzkennzahlen ('ratios') eines Unternehmens die Wahrscheinlichkeit eines Defaults vorauszusagen, bzw., daraus abgeleitet, ob das Unternehmen zu der Klasse der Unternehmen gehört, die zahlungsunfähig werden (Klasse 'Default'), oder zur Klasse derer, die ihren Kredit ordnungsgemäss zurückzahlen werden (Klasse 'non-Default')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grundidee:**\n",
    "\n",
    "Die Wahrschienlichkeit eines Unternehmens, zahlungsunfähig zu werden hängt von den Ratios ab, z.B. dem Debt-to-Equity Ratio. Bei diesem Ratio erwarten wir folgendes Verhalten: Ist das Ratio sehr klein (d.h im Verhältnis zum Eigenkapital sehr wenig Schulden), so ist die Wahrscheinlichkeit eines Defaults sehr klein. Ist das Ratio sehr gross (sehr viele Schulden) so ist die Wahrscheinlichkeit eines Defaults sehr gross. Um die *Ausfallwahrscheinlichkeit* (Wahrscheinlichkeit eines Defaults) $p(x)$ in Abhängigkeit eines solchen Ratios $x$ zu modellieren, benötigen wir also eine Funktion, die für sehr kleine $x$ einen Wert nahe 0 annimmt und dann für grösser werdende $x$ (in kontinuierlicher Weise) auf einen Wert nahe 1 ansteigt. Die Logistische Funktion\n",
    "$$\n",
    "y = p(x) = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}}\n",
    "$$\n",
    "zeigt genau ein solches Verhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LogFunct](LogFunct.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bemerkung:**\n",
    "\n",
    "Die logistische Funktion hängt (im einfachsten Fall) ab von den Features $x$ und den **Modellparametern** $\\beta_0$ und $\\beta_1$. Durch diese beiden Parameter wird die Position (durch $\\beta_0$) und die Steilheit (durch $\\beta_1$) des Übergangs von $p(x)\\approx 0$ auf $p(x)\\approx 1$ bestimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst wollen wir die Form der logistischen Funktion bei verschiedenen Parametern $\\beta_0$ und $\\beta_1$ etwas besser kennenlernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitung: wir werden numpy und seaborn benötigen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden erstellen wir zunächst einen Vektor *x_werte*, der 200 Werte von -10 bis +10 in Schritten von 0.1 enthält. Dafür benutzen wir die numpy Funktion *arange()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir definieren zunächst eine Reihe von x-Werten, an denen wir die logistische Funktion auswerten wollen\n",
    "x_werte = np.arange(-10,10,0.1)\n",
    "x_werte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt legen wir die Parameter der logistischen Funktion in den Variablen *beta_0* und *beta_1* fest. Wir könnten hier im Prinzip beliebige reelle Zahlen einsetzen, benutzen aber zunächst mal die einfachsten, nämlich $\\beta_0 = 0$ und $\\beta_1 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter der logistischen Funktion festlegen.\n",
    "# Bemerkung: Diese Werte werden sie später im Rahmen des Aufgabenblocks 1 verändern.\n",
    "beta_0 = 0\n",
    "beta_1 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe der numpy *Vektor Operationen* können wir nun ganz einfach **in einem Schritt** für alle Elemente des Vektors *x_werte* die entsprechenden Funktionswerte berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktionswerte berechnen (Beachten Sie, da x_werte ein Vektor ist, ist auch f_x ein Vektor!)\n",
    "f_x = 1/(1+np.exp(-(beta_0 + beta_1*x_werte)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schauen Sie sich den Vektor f_x an. Was sind die ersten und die letzten Werte? Machen die Sinn?\n",
    "f_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Tabelle der Werte von *f_x* erkennen wir noch nicht sehr viel. Viel anschaulicher ist ein Plot der Funktion. Wir kennen schon einige Plot-Funktionen aus seaborn. Da wir die Funktion als eine \"Linie\" darstellen möchten, eignet sich hier der seaborn *lineplot()*. Wir übergeben der Funktion *lineplot()* als x-Koordinaten die Werte des Vektors *x_werte* und als y-Koordinaten die Werte des Vektors *f_x*. Details der Möglichkeiten und Parameter der Funktion *lineplot()* siehe: https://seaborn.pydata.org/generated/seaborn.lineplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion darstellen: das geht mit einem seaborn lineplot\n",
    "sns.lineplot(x = x_werte, y = f_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation/Beobachtung**: Der Parameter $\\beta_0$ bestimmt die Position des Übergangs. Der Parameter $\\beta_1$ die Steilheit des Übergangs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exkurs: Die Matplotlib Plot Funktion\n",
    "\n",
    "Die seaborn Funktion *lineplot()* ist sehr mächtig und eigentlich für so einen einfachen Plot wie oben ein bischen ein \"overkill\". Für solche *einfachen* Plots ist es manchmal fast einfacher, diese direkt mit den Plot Funktionen des Basis-Pakets **matplotlib.pyplot** zu erstellen. Der matplotlib Funktion *plot()* können dabei als erste beiden Argumente die (Listen der) x-Werte und y-Werte der zu plottenden Punkte übergeben werden. Einige mögliche Optionen zur Verschönerung der Plots sind *color=*, *linestyle=*, *linewidth=*, *marker=* und *markersize=*. Um Genaueres über diese optionalen Parameter zu erfahren, siehe z.B. https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.plot.html unter \\**kwargs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die matplotlib plot Funktionen importieren. Sind ab hier mit dem Prefix plt. ansprechbar.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die matplotlib.plt Funktion\n",
    "plt.plot(x_werte, f_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exkurs: Ende"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lernprozess der Logistischen Regression und Cross-Entropy\n",
    "\n",
    "Bei der Logistischen Regression ist es Ziel des **Lernprozesses** (Fit des Modells an die Daten), bei **gegebenen Features** $x$ der Unternehmen im Datensatz die **Parameter** $\\beta_0$ und $\\beta_1$ der Logistischen Funktion so zu **bestimmen**, dass die Funktion $p(x; \\beta_0,\\beta_1)$ für **alle** Unternehmen im Sample die **wahren Ausfallwahrscheinlichkeiten so gut als möglich reproduziert**.\n",
    "\n",
    "**Problem:** Die wahren Ausfallwahrscheinlichkeiten der Unternehmen im Datensatz kennen wir gar nicht! Wir wissen nur, ob das Unternehmen tatsächlich ausgefallen ist oder nicht.\n",
    "\n",
    "Die Lösung ist, ein geeignetes **Fehlermass** für die Vorhersagen des Modell zu definieren. Wir brauchen also ein Mass, das uns sagt, wann eine vorhergesagte Ausfallwahrscheinlichkeit gut ist, und wann sie schlecht ist.\n",
    "Für ein Unternehmen $i$ mit Feature $x_i$, welches **tatsächlich zahlungsunfähig** geworden ist, sollte der **Fehler gross** sein, wenn das Modell *fälschlicherweise* eine **kleine Ausfallwahrscheinlichkeit** $p_i = p(x_i; \\beta_0, \\beta_1)$ vorausgesagt hat. Umgekehrt sollte der **Fehler klein** sein, wenn das Modell *richtigerweise* eine **grosse Ausfallwahrscheinlichkeit** vorausgesagt hat. Genau diese Eigenschaft hat die folgende **Fehlerfunktion** $J_i(\\beta_0, \\beta_1)$, die die Grösse des Fehlers angibt:\n",
    "\n",
    "$$\n",
    "J_i(\\beta_0, \\beta_1) = -\\log(p_i) \n",
    "$$\n",
    "\n",
    "Wir sehen: Für $p_i \\rightarrow 0$ geht $\\log(p_i)\\rightarrow -\\infty$, d.h. bei kleinen vorausgesagten Ausfallwahrscheinlichkeiten $p_i$ wird der Fehler $J_i$ sehr gross (wir betrachten hier ja ein Unternehmen, das tatsächlich zahlungsunfähig wurde). Umgekehrt gilt für $p_i\\rightarrow 1$, dass $\\log(p_i)\\rightarrow 0$; d.h. für grosse vorausgesagte Ausfallwahrscheinlichkeiten $p_i$ (nahe 1) wird der Fehler $J_i$ verschwindend klein (da es ja richtig ist, für ein Unternehmen, das tatsächlich zahlungsunfähig wurde, eine hohe Ausfallwahrscheinlichkeit vorauszusagen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns nun die Funktion $J(p)$ für verschiedene Werte von $p$ in einem Plot an (so wie wir das oben für die Logistische Funktion selbst gemacht haben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der p-Werte zwischen 0 und 1 generieren\n",
    "p_werte = np.arange(0.01, 0.99, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der Funktionswerte J(p) berechnen\n",
    "J_p = -np.log(p_werte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion j(p) darstellen\n",
    "sns.lineplot(x = p_werte, y = J_p)\n",
    "plt.title('Fehlerfunktion für ein Unternehmen, das zahlungsunfähig geworden ist')\n",
    "plt.xlabel('Vorausgesagte Ausfallwahrscheinlichkeit')\n",
    "plt.ylabel('Resultierender Fehler J(p)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Datensatz hat es aber nicht nur Unternehmen, die tatsächlich zahlungsunfähig geworden sind, sondern auch viele, die **nicht zahlungsunfähig** geworden sind. Für ein Unternehmen, das in Wahrheit **nicht zahlungsunfähig** geworden ist, müsste die Fehlerfunktion genau **umgekehrt** wie oben sein, nämlich so aussehen:\n",
    "\n",
    "$$\n",
    "J_i(\\beta_0, \\beta_1) = -\\log(1-p_i)\n",
    "$$\n",
    "\n",
    "Schauen wir uns auch diese Funktion in einem Plot an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_werte = np.arange(0.01, 0.99, 0.01)   # Vektor der x-Werte\n",
    "J_p_nd = -np.log(1-p_werte)                # Vektor der Funktionswerte J(p) \n",
    "sns.lineplot(x = p_werte, y = J_p_nd)\n",
    "plt.title('Fehlerfunktion für ein Unternehmen, das NICHT zahlungsunfähig geworden ist')\n",
    "plt.xlabel('Vorausgesagte Ausfallwahrscheinlichkeit')\n",
    "plt.ylabel('Resultierender Fehler J(p)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der **Gesamtfehler** des Modells ergibt sich dann durch Summation der Vorhersagefehler jedes einzelnen Unternehmens und kann folgendermassen geschrieben werden:\n",
    "\n",
    "$$\n",
    "J(\\beta_0, \\beta_1) = -\\sum_{i=1}^n\\{ y_i\\log(p_i) + (1-y_i)\\log(1-p_i)\\}\n",
    "$$\n",
    "\n",
    "wobei $y_i$ der Label des Unternehmens $i$ ist. Also $y_i = 1$, falls das Unternehmen $i$ tatsächlich zahlungsunfähig geworden ist, und sonst 0.\n",
    "\n",
    "**Bemerkung**: In der Summation über alle Unternehmen wird bei jedem Summanden jeweils nur ein Term \"behalten\". Für ein Unternehmen *i*, das tatsächlich ausgefallen ist, gilt $y_i=1$. Dann wird der erste Term $y_i\\log(p_i)$ behalten, aber der zweite Term, $(1-y_i)\\log(1-p_i)$ wird wegen dem Faktor $(1-y_i)$ gleich Null. Für ein Unternehmen, das nicht ausgefallen ist, mit $y_i=0$ ist es genau umgekehrt.\n",
    "\n",
    "Im Rahmen des Machine Learning wird eine solche Fehlerfunktion $J(\\beta_0, \\beta_1)$ auch **Cost-Function** genannt. Die soeben definierte Funktion $J(\\beta_0, \\beta_1)$ wird **Cross-Entropy** genannt. Sie wird üblicherweise bei der Logistischen Regression als Cost-Function genommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimierung der Cost-Function\n",
    "\n",
    "Wir haben oben gesehen, dass die Logistische Funktion die **Parameter** $\\beta_0$ und $\\beta_1$ enthält, welche **so** zu **bestimmen** sind, **dass** - für den gegebenen Datensatz - der **Fehler** $J(\\beta_0, \\beta_1)$ **minimiert** wird. Manchmal kann man ein solches Minimum *analytisch* finden durch Nullsetzen der Ableitungen. Im Machine Learning, insbesondere wenn man es mit sehr vielen Features oder komplexeren Modellen zu tun hat, ist es aber fast üblicher, dieses Minimum mit Hilfe *numerischer Verfahren* zu finden.\n",
    "\n",
    "Für uns sind die mathematisch/numerischen Details der Prozedur, wie das Minimum gefunden wird hier irrelevant. Hauptsache die optimalen Parameter $\\beta_0$ und $\\beta_1$ werden gefunden, die die Cost-Function minimieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Von **Wahrscheinlichkeiten** zu **Klassenzugehörigkeiten**\n",
    "\n",
    "Haben wir durch Minimieren der Cost-Function die optimalen Parameter $\\beta_0$ und $\\beta_1$ gefunden, so liefert die resultierende Logistische Funktion\n",
    "\n",
    "$$\n",
    "p(x) = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}}\n",
    "$$\n",
    "\n",
    "für jeden Feature-Vektor $x$ die Wahrscheinlichkeit eines Defaults $p(x)$. Wie kommen wir nun von **Wahrscheinlichkeiten** zu **Klassenzugehörigkeiten**, d.h. zu einer eindeutigen Voraussage: das Unternehmen zahlungsunfähig, ja oder nein?\n",
    "\n",
    "**Vorgehen**:\n",
    "* Man definiert eine **Threshold** Ausfallwahrscheinlichkeit $p_{thr}$.\n",
    "* Ist die vorausgesagte Ausfallwahrscheinlichkeit $p(x)$ grösser als der Threshold, wird das Unternehmen der Klasse *Default* zugeordnet, ansonsten der Klasse *Non-Default*.\n",
    "* Der Standarwert für den Threshold ist $p_{thr} = 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anwendungsbeispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen die Logistische Regression am oben beschriebenen Datensatz mit Unternehmensdaten ausprobieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Datensatz heisst 'DefaultData.csv'\n",
    "daten = pd.read_csv('DefaultData.csv', index_col = 0)\n",
    "daten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die normlerweise notwendige Analyse/Visualisierung der Daten überspringen wir hier grossteils. Nur einige elementare Charakteristika:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl Unternehmen im Datensatz\n",
    "n_samples = len(daten)\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl zahlungsunfähiger Unternehmen\n",
    "n_defaults = daten['status'].sum()\n",
    "n_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anteil zahlungsunfähiger Unternehmen\n",
    "n_defaults / n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden verwenden wir **alle** Ratios als Features und das Feld *status* als Label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matrix und Labels\n",
    "X = daten[['ratio1', 'ratio2', 'ratio3', 'ratio4', 'ratio5']].values\n",
    "y = daten['status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zur Kontrolle: die Feature-Matrix\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zur Kontrolle: der Vektor der Labels\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse mittels Logistischer Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn gibt es für die Logistische Regression die Funktion *LogisticRegression()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell Logistische Regression verfügbar machen\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell definieren\n",
    "model = LogisticRegression(solver = 'lbfgs', penalty = None)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die scikit-learn Funktion *LogisticRegression()* hat etliche Parameter. Für uns wichtig sind lediglich die Parameter:\n",
    "\n",
    "* *penalty = None*: Regularisierungsparameter: wir verwenden hier *keine* Regularisierung.\n",
    "* *solver = ...*: Der zu verwendende Algorithmus für die numerische Minimierung der Cost-Function. Wir belassen das auf dem Default Wert 'lbfgs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Modell (auf dem gesamten Datensatz) trainieren\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch Aufruf der Methode *fit()* werden die optimalen Parameter $\\beta_0$ und $\\beta_1$ der Logistischen Funktion durch Minimieren der oben beschriebenen Cross-Entropy Cost-Function gefunden. Bemerkung: da wir hier 4 Features verwenden, gibt es insgesamt 5 Parameter, nämlich: $\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4$ und $\\beta_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So kann man sich die (\"erlernten\") Parameter anschauen.\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem trainierten Logistischen Modell kann man nun Vorhersagen für die **Wahrscheinlichkeit** eines Defaults eines Unternehmens machen. Die scikit-learn Methode für die Vorhersage dieser Wahrscheinlichkeit ist *predict_proba()*. Als Argument müssen wir eine Feature-Matrix übergeben. Die Funktion liefert dann für jede Zeile in der Feature-Matrix für jede mögliche Klasse die Wahrscheinlichkeit zu dieser Klasse zu gehören. In unserem Fall gibt es genau zwei Klassen, nämlich die Klasse 0 (non-Default) und die Klasse 1 (Default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Sample Voraussagen der non-Default- (erste Spalte) und Default- (zweite Spalte) Wahrscheinlichkeiten\n",
    "# für die ersten 10 Unternehmen\n",
    "model.predict_proba(X[:10])\n",
    "# Bemerkung: da es nur die Klassen 0 und 1 gibt, muss die Wahrscheinlichkeit, zur Klasse 1 zugehören,\n",
    "# genau 1 - die Wahrscheinlichkeit, zur Klasse 0 zu gehören, sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigentlich benötigen wir nur die vorausgesagte Default-Wahrscheinlichkeiten:\n",
    "# Wir behalten im von der Methode predict_proba() gelieferten Array NUR DIE ZWEITE Spalte\n",
    "y_pred_proba = model.predict_proba(X[:10])[:,1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Logistische Regression sagt also für das erste Unternehmen im Datensatz eine Ausfallwahrscheinlichkeit von 45% voraus, während die vorausgesagte Ausfallwahrscheinlichkeit für das zweite Unternehmen nur 1% beträgt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns im Folgenden die für den gesamten Datesatz prognostizierten Ausfallwahrscheinlichkeiten genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vektor der Ausfallwahrscheinlichkeiten aller Unternehmen im Datensatz\n",
    "y_pred_proba = model.predict_proba(X)[:,1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Verteilung der prognostizierten Ausfallwahrscheinlichkeiten\n",
    "sns.histplot(y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir entscheiden müssen üder die Vergabe eines Kredites an ein Unternehmen, interessiert uns eigentlich einfach, ob das Unternehmen den Kredit ordnungsgemäss zurückzahlen wird oder zahlungsunfähig wird; d.h. wir wollen das Unternehmen einer von zwei Klassen zuordnen:\n",
    "\n",
    "* Klasse 0: Unternehmen wird **nicht** zahlungsunfähig (zahlt Kredit ordnungsgemäss zurück)\n",
    "* Klasse 1: Unternehmen wird zahlungsunfähig (zahlt den Kredit **nicht** zurück)\n",
    "\n",
    "Aus den vom Logistischen Modell vorhergesagten **Ausfallwahrscheinlichkeiten** kann man nun die Klassenzugehörigkeit ableiten, indem man einen **Threshold** $p_{thr}$ definiert, ab dem das Unternehmen als \"wird zahlungsunfähig\" eingestuft wird. Mit einem Threshold von $p_{thr} =0.5$ erhalten wir folgende vorausgesagte Klassenzugehörigkeiten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_proba > 0.5)*1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Einfacher** erhält man die vorhergesagte Klassenzugehörigkeit bei einem Threshold von $p_{thr} = 0.5$ **direkt** mit der scikit-learn Methode *predict()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassenzugehörigkeit bei Threshold 0.5:\n",
    "model.predict(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleichen wir diese Voraussagen mit der **wahren** Klassenzugehörigkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere vorausgesagten Klassenzugehörigkeiten waren für diese ersten 10 Unternehmen also nicht sehr gut. Das Machine Learning Modell hat keine der beiden Ausfälle erkannt.\n",
    "\n",
    "**Beobachtung**: Durch Verändern des Thresholds können wir die vorausgesagten Klassenzugehörigkeiten beeinflussen. Mit einem tieferen Threshold werden wir mehr Ausfälle prognsotizieren, mit einem höheren Threshold weniger. Wir probieren also verschiedene Thresholds aus und schauen uns die resultierenden Prognosen an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir andere Thresholds als $p_{thr} = 0.5$ verwenden wollen, so müssen wir die Klassifizierung **\"von Hand\"** vornehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So erhalten wir die prognostizierten Klassenzugehörigkeiten bei einem Threshold p_thr = 0.3\n",
    "y_pred = (y_pred_proba > 0.3) * 1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Anzahl vorhergesagter Defaults mit den tatsächlichen:\n",
    "print('Anzahl vorausgesagter Defaults:', y_pred.sum())\n",
    "print('Anzahl tatsächlicher Defaults:', y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl korrekter Vorhersagen\n",
    "(y_pred == y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anteil korrekter Vorhersagen (bei Threshold p_thr = 0.3)\n",
    "(y_pred == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACHTUNG: mit der score() Methode erhalten wir den Anteil korrekter Vorhersagen bei einem Threshold von p_thr = 0.5!!!\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diskussion der Modell-Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wollen wir die Performance des Modells genauer anschauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: Der *naive* Schätzer/ Das *naive* Modell\n",
    "\n",
    "Ob sich der Aufwand eines (mehr oder weniger) komplizierten Machine Learning Modells lohnt, ergibt sich durch **Vergleich mit einem einfacheren Modell**. Das einfachst mögliche Modell ist der sogenannte **Naive Schätzer**. Dieser sagt bei Klassifikationsproblemen **für alle** Datenpunkte **immer** die Klassenzugehörigkeit voraus, die im Sample am häufigsten vorkommt. In unserem Fall ist die Häufigste Klasse der *Non-Default* (fast 90% der Unternehmen werden nicht zahlungsunfähig); d.h. der naive Schätzer würde in unserem Fall für **alle** Unternehmen voraussagen, dass sie **nicht** zahlungsunfähig werden.\n",
    "\n",
    "Was wäre der (Genauigkeits-)Score des Naiven-Schätzers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst die Voraussagen des naiven Schätzers (ein Vektor mit alles Nullen)\n",
    "y_pred_naiv = 0*y\n",
    "y_pred_naiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Voraussagen mit der wahren Klassenzugehörigkeit\n",
    "(y_pred_naiv == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese ganz simple, \"naive\" Modell, hat also bereits einen score von fast 90%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andere Performance Masse: *True Positive Rate* und *False Positive Rate*\n",
    "\n",
    "Die Genauigkeit ist in vielen Fällen (so auch in diesem) nicht unbedingt das beste Mass, die Qualtiät eines Algorithmus zu beurteilen.\n",
    "\n",
    "In unserem Beispiel kann der Schaden gewaltig sein, falls man einen Kredit an ein Unternehmen vergibt, das später zahlungsunfähig wird. Man verliert in dem Fall den gesamten Kreditbetrag! Andererseits verliert man nur den Zinsertrag (bzw. die Zinsmarge) als Einkommen, wenn man einem Unternehmen, das in der Lage wäre, den Kredit korrekt zurück zu zahlen, den Kredit verweigert. Dieser Zinsertrag oder die Zinsmarge ist aber üblicherweise nur ein Bruchteil des gesamten Kreditbetrags.\n",
    "\n",
    "Schlussfolgerung: in diesem Beispiel wiegen Fehler \"Kredit gegeben, Unternehmen zahlt nicht zurück\" also viel schwerer als Fehler \"kein Kredit gegeben, Unternehmen hätte aber zurückgezahlt\". Bei der Berechnung der Vorhersagegenauigkeit wiegen aber beide Fehler genau gleich schwer. Für die \"ökonomische\" Beurteilung der Qualität des Algorithmus ist also die Vorhersagegenauigkeit nicht geeignet.\n",
    "\n",
    "In unserem Fall lohnt es sich also sehr, wenn man in der Lage ist, Unternehmen, die später zahlungsunfähig werden, bereits bei der Kreditvergabe korrekt zu identifizieren und diesen Unternehmen erst gar keinen Kredit zu geben. Wie misst man, ob der Algorithmus dazu in der Lage ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir kennen bereits die **Confusion-Matrix**. Sie zeigt genau, welche Art von Fehlern gemacht wurden. Wie sieht die Confusion-Matrix des naiven Modells aus? Wie die der Logistischen Regression? Wenn sie sich auch in der Verhersagegenauigkeit kaum unterscheiden, unterscheiden Sie sich dann vielleicht aber in der Art der Fehler die gemacht werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn Funktion importieren\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Konfusionsmatrix des naiven Modells**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_naiv = confusion_matrix(y, y_pred_naiv)\n",
    "cm_naiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- der naive Schätzer sagt für alle Unternehmen \"non-Default\" voraus, d.h. wir haben in der Confusion-Matrix nur Werte in der ersten Spalte.\n",
    "- Alle 498 Unternehmen, die zahlungsunfähig wurden, wurden falsch klassifiziert. Wir haben also hier nur (die sehr teuren) Fehler vom Typ \"Kredit vergeben, Unternehmen zahlt nicht zurück\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Konfusionsmatrix des logistischen Regressionsmodells (bei Threshold $p_{thr} = 0.5$)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voraussagen der Logistischen Regression bei Threshold 0.5\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix der Logistischen Regression mit Threshold 0.5\n",
    "cm_logreg = confusion_matrix(y, y_pred)\n",
    "cm_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Der Logistischen Regression gelang es, die kostspieligen Feher vom Typ \"Kredit gegeben, nicht zurückgezahlt\" zu reduzieren. Damit konnte viel Schaden abgewandt werden. Von den 498 zahlungsunfähigen Unternehmen konnten immerhin 103 korrekt als solche vorausgesagt werden. (Diese 103 Unternehmen würden bei der Kreditvergabe abgelehnt.)\n",
    "- Allerdings macht die Logistische Regression nun auch einige Fehler vom Typ \"Kredit verweigert, wäre aber zurückgezahlt worden\". Dadurch entgehen dem Unternehmen Zinseinnahmen. 40 \"guten\" Unternehmen wurde unnötigerweise ein Kredit verweigert.\n",
    "- Welcher der beiden Effekte nun überwiegt, hängt vom konkreten Geschäftsmodell ab.\n",
    "- Typischerweise ist es in der Praxis so, dass der Verlust durch einen fälschlich vergebenen Kredit gerne mal so schwer wiegt, wie der Verdienstausfall durch 10 Kredite, die man unnötigerweise abgelehnt hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aus der Confusion-Matrix abgeleitete Performance Masse: True Positive Rate und False Positive Rate\n",
    "\n",
    "Wir bestimmen nun mit Hilfe der Confusion-Matrix zwei weitere Performance Masse: die **True Positive Rate** (**TPR**) und die **False Positive Rate** (**FPR**). Diese beiden Performance-Masse zeigen genau, welche der obigen beiden Arten von Fehlern bei der Klassifikation gemacht wurden.\n",
    "\n",
    "Beachten Sie, in unserem Beispiel bedeutet \"positive\": zur Klasse 1 zugehörig, d.h. zahlungsunfähig werden.\n",
    "\n",
    "Wir verwenden im Folgenden die oben berechnete Confusion-Matrix des Logistischen Modells um die True Positive Rate Schritt für Schritt zu bestimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst die **Positives**, also die Anzahl der Unternehmen, die tatsächlich zahlungsunfähig wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das ist die Summe der Werte in der 2. Zeile der Confusion Matrix\n",
    "n_positives = cm_logreg[1].sum()   # Beachten Sie: die zweite Zeile hat die Index-Position 1\n",
    "n_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schliesslich die **True Positives**, also die Anzahl der Unternehmen, für die der Algorithmus **korrekterweise**  die Zahlungsunfähigkeit vorausgesagt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das ist der Wert rechts unten in der Confusion-Matrix\n",
    "true_positives = cm_logreg[1,1]\n",
    "true_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Anteil der tatsächlichen Defaults (*Positives*), die vom Algorithmus korrekterweise auch als Defaults vorausgesagt wurden (*True Positives*), ist die **True Positive Rate**:\n",
    "\n",
    "True Positive Rate = True Positives / Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die True Positive Rate ist der Quotient:\n",
    "true_positives / n_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Anteil der wahren Defaults, die vom Algorithmus korrekterweise als solche erkannt wurden, nennt sich die **True Positive Rate** oder **TPR**. Im Kontext des Machine Learning wird die TPR manchmal auch **Recall-Score** genannt, so auch in scikit-learn. Scikit-learn stellt zur Berechnung der True Positive Rate die Fuktion *recall_score()* zur Verfügung. Dieser Funktion müssen als Parameter die wahre Klassenzugehörigkeit und die vorausgesagte Klassenzugehörigkeit übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die scikit-learn Funktion importieren\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die True Positive Rate berechnen \n",
    "tpr = recall_score(y, y_pred)\n",
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Logistische Regression war also in der Lage, etliche (gut 20%) der späteren Zahlungsausfälle korrekt vorauszusagen. Ein gutes Modell sollte eine **möglichst hohe** *True Positive Rate* haben. Das 'perfekte' Modell hätte eine TPR von 1!\n",
    "\n",
    "**Bemerkungen**:\n",
    "\n",
    "* Das naive Modell hat eine TPR von 0, da alle Unternehmen als non-Defaults klassifiziert wurden, also gar keine *positives* erkannt wurden.\n",
    "* Ein (naives) Modell, das **alle** Unternehmen als Defaults klassifizieren würde, hätte eine TPR von 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider ist es üblicherweise so, dass je besser ein Modell in der Lage ist, die wahren Defaults korrekt als solche zu klassifizieren, desto öfter macht es den Fehler, in Wahrheit 'gesunde' Unternehmen (non-Deafults) fälschlicherweise auch als Defaults zu klassifizieren. Der Anteil der 'gesunden' Unternehmen (non-Defaults), die **fälschlicherweise** vom Modell als Defaults klassifiziert werden, heisst **False Positive Rate** oder **FPR**. Für die *False Positive Rate* gibt es keine eigene Funktion in scikit-learn, aber sie kann natürlich aus der Confusion-Matrix berechnet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst die **Negatives**, also die Anzahl der Unternehmen, die tatsächlich **nicht** zahlungsunfähig wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das ist die Summe der Werte in der ersten Zeile der Confusion-Matrix\n",
    "n_negatives = cm_logreg[0].sum()  # Beachten Sie: die erste Zeile hat die Index-Position 0 \n",
    "n_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schliesslich die **False Positives**, also die Anzahl der Unternehmen, für die der Algorithmus **fälschlicherweise** die Zahlungsunfähigkeit vorausgesagt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives: Anzahl Unternehmen, die tatsächlich non-Defaults sind, aber fälschlicherweise als Defaults vorausgesagt wurden\n",
    "# Das ist der Wert in der Confusion-Matrix rechts oben\n",
    "false_positives = cm_logreg[0,1]\n",
    "false_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Anteil der \"gesunden\" Unternehmen (*Negatives*), die vom Algorithmus fälschlicherweise als Defaults vorausgesagt wurden (*False Positives*), ist die **False Positive Rate**:\n",
    "\n",
    "False Positive Rate = False Positives / Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive Rate\n",
    "fpr = false_positives/ n_negatives\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Logistische Regression hätte also bei einigen (bei knapp 1%) 'gesunden' Unternehmen zu unrecht zur Ablehnung des Kreditantrags geführt, da das Modell fälschlicherweise einen Zahlungsausfall vorausgesagt hätte. Das ist natürlich nicht gut. Ein gutes Modell sollte eine möglichst geringe *False Positive Rate* haben. Das perfekte Modell hätte eine FPR von 0!\n",
    "\n",
    "**Bermekungen:**\n",
    "\n",
    "* Die FPR des naiven Modells (alle Unternehmen sind non-Defaults) wäre 0. Super!\n",
    "* Die FPR des naiven Modells (alle Unternehmen sind Defaults) wäre 1. Super-Schlecht!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammenfassung:\n",
    "\n",
    "Wir haben gesehen, dass ein **gutes Modell** sowohl eine **möglichst hohe TPR**, als auch eine **möglichst niedrige FPR** haben sollte. Wenn wir die Qualität zweier Modelle vergleichen wollen, genügt es daher nicht, **nur** die TPR oder **nur** die FPR anzuschauen, sondern beide Werte sind gemeinsam zu betrachten und gegeneinander abzuwägen.\n",
    "\n",
    "Wie der Ausgleich zwischen hoher TPR und tiefer FPR zu finden ist, hängt vom Anwendungsfall ab: z.B. wie schlimm ist es, einen 'guten Kunden' fälschlicherweise abzulehnen und wie nützlich ist es einen 'schlechten Kunden' richtigerweise abzulehnen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exkurs: Beispiel Kreditgeschäft**\n",
    "\n",
    "Nemen Sie an, die Bank verliert bei der Vergabe eines Kredits an einen Kunden, der später nicht in der Lage ist, diesen zurück zu zahlen, den gesamten Kreditbetrag von CHF 100'000. Lehnt die Bank einen Kunden ab, der eigentlich in der Lage wäre den Kredit (samt Zinsen) zurück zu zahlen, so verliert sie CHF 2'500 (Zins-)einkommen.\n",
    "\n",
    "Ein Algorithmus habe 50 Zahlungsausfälle korrekt vorausgesagt, allerdings 1390 (gute) Kunden fälschlicherweise abgelehnt. Was wäre der Nettoeffekt (in CHF) dieses Algorithmus für die Bank (verglichen mit dem \"Base Case\", dass alle Anträge angenommen würden)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vermiedene Verluste (nicht zurückbezahlte Kredite):\n",
    "verm_verl = 50* 100000\n",
    "verm_verl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verloren gegangenes Einkommen (ablehnen \"guter\" Kunden)\n",
    "verl_eink = 1390*2500\n",
    "verl_eink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoeffekt: Vermiedene Verluste wirken Positiv, entgangenes Einkommen negativ\n",
    "verm_verl - verl_eink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obwohl es also auf den ersten Blick desaströs aussieht, 1390 (gute) Kunden abzulehnen, hat sich der Einsatz des Algorithmus finanziell doch gelohnt, da es gelang die sehr grossen Verluste durch die 50 Ausfälle durch \"schlechte\" Kunden zu vermeiden.\n",
    "\n",
    "**Exkurs Ende**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Receiver Operating Characteristic - ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Logistische Regression so wie sie oben implementiert wurde war in der Lage, etliche Defaults korrekt vorherzusagen (recht hohe TPR), wobei sie aber auch ein paar Fehler machte (zwar kleine FPR, aber nicht 0). Man hätte die Klassifizierung aber auch anders machen können - mit genau demselben Modell! Die **Logistische Regression** selbst **modelliert** ja zunächst nur die **Ausfallwahrscheinlichkeiten**. Erst durch Einführen eines **Thresholds** $p_{thr}$ haben wir die Grenze zwischen 'Default' (Kredit Ablehnen) und non-Default (Kredit Annehmen) festgelegt. Oben wurde diese Klassifikation mit $p_{thr} = 0.5$ durchgeführt.\n",
    "\n",
    "Ein **anderer Threshhold** hätte zu einer **anderen Klassifikation** der Unternehmen geführt. Vielleicht hätte man durch einen anderen Threshold sogar eine bessere Performance erzielen können?\n",
    "\n",
    "**Bemerkungen:**:\n",
    "* Je höher der Threshold, desto tiefer die FPR (gut!) aber auch die TPR (schlecht!).\n",
    "* Je niedriger der Threshold, desto höher die FPR (schlecht!) aber auch die TPR (gut!).\n",
    "* Der Einfluss der Veränderung des thresholds auf dei Vorhersagegenauigkeit ist unklar, sie kann steigen oder fallen oder (fast) unverändert bleiben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beispiel**: die Confusion-Matrix, Accuracy, TPR und FPR unseres Logistischen Modells *model* für verschiedene Thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die verhergesagten Ausfallwahrscheinlichkeiten\n",
    "y_pred_proba = model.predict_proba(X)[:,1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Klassifikation bei gegebenem Threshold, z.b. p_thr = 0.25\n",
    "y_pred_thr = (y_pred_proba > 0.25)*1\n",
    "y_pred_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die resultierende Konfusionsmatrix\n",
    "cm_thr = confusion_matrix(y, y_pred_thr)\n",
    "cm_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Performance Masse Accuracy, TPR und FPR\n",
    "print('Accuracy:', (cm_thr[0,0] + cm_thr[1,1]) / cm_thr.sum())\n",
    "print('TPR:', cm_thr[1,1]/cm_thr[1].sum())\n",
    "print('FPR:', cm_thr[0,1]/cm_thr[0].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Diagramm, das den **Verlauf von TPR und FPR für **verschiedene Thresholds** zeigt, ist die **Receiver Operating Characteristic**, auch **ROC-Kurve** genannt.\n",
    "\n",
    "Scikit-learn kennt hier die Funktion *roc_curve()*. Sie benötigt als Input die **wahre Klassenzugehörigkeit** und die **vorausgesagte Wahrscheinlichkeit**, zur Klasse 1 (Default) zu gehören."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_curve() liefert drei Listen: FPR, TPR und verwendete Thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR und FPR in Abhängigkeit des Thresholds\n",
    "plt.title('TPR (grün) und FPR (rot) in Abhängigkeit des Thresholds')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Rate')\n",
    "plt.plot(thresholds[1:], fpr[1:], color = 'red') # Für eine schönere Darstellung lassen wir den ersten Wert (Indexposition 0) weg\n",
    "plt.plot(thresholds[1:], tpr[1:], color = 'green') # Für eine schönere Darstellung lassen wir den ersten Wert (Indexposition 0) weg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **ROC-Kurve** stellt nun die **True Positive Rate als Funktion der False Positive Rate** dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-Kurve\n",
    "plt.title('ROC Kurve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bemerkungen:\n",
    "\n",
    "* Der naive Schätzer \"alle sind non-Defaults\" entspricht $p_{thr} = 1$ und hat die FPR = 0 und TPR = 0\n",
    "* Der naive Schätzer \"alle sind Defaults\" entspricht $p_{thr} = 0$ und hat die FPR = 1 und TPR = 1\n",
    "* Erhöht man den Threshold $p_{thr}$ von 0 auf 1, geht man im Diagramm der Linie entlang von oben rechts nach unten links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wichtige Bemerkung**:\n",
    "\n",
    "Welches der optimale Threshold ist, hängt vom einzelnen Anwendungsfall ab. Aber grundsätzlich gilt: Je weiter die Kurve nach oben durchgebogen ist, desto besser ist das Modell. Warum?\n",
    "\n",
    "Ein 'einfaches' Mass das reflektiert, wie stark die Kurve nach oben durchgebogen ist, ist die sogenannte **Area Under the Curve (AUC)**. Sie misst die gesamte Fläche unter der Kurve. In scikit-learn gibt es dazu die Funktion *roc_auc_score()*. Die Argumente dieser Funktion sind dieselben wie die der Funktion *roc_curve()*, nämlich die wahre Klassenzugehörigkeit und die vorhergesagte Wahrscheinlichkeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viel schneller geht die Analyse des Verhaltens des Modells bei verschiedenen Thresholds mit Hilfe der in scikit-learn vordefinierten Klasse *RocCurveDisplay()* und den in dieser Klasse definierten Methoden *from_predictions()* und *from_estimator()*.\n",
    "\n",
    "Als Parameter benötigt die Methode *from_predictions()* die wahre Klassenzugehörigkeit und die vom Modell vorausgesagte Wahrscheinlichket der Zugehörigkeit zur Klasse 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aus den Vorhersagen des Modells\n",
    "RocCurveDisplay.from_predictions(y, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Methode *from_estimator()* benötigt als Parameter das trainierte Modell, sowie die Features und Labels der zu verwendenden Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativ: direkt mit Hilfe des trainierten Modells\n",
    "RocCurveDisplay.from_estimator(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
